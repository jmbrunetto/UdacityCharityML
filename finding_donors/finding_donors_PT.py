#!/usr/bin/env python
# coding: utf-8

# # Nanodegree Engenheiro de Machine Learning
# ## Aprendizado Supervisionado
# ## Projeto: Encontrando doadores para a *CharityML*

# Seja bem-vindo ao segundo projeto do Nanodegree Engenheiro de Machine Learning! Neste notebook, voc√™ receber√° alguns c√≥digos de exemplo e ser√° seu trabalho implementar as funcionalidades adicionais necess√°rias para a conclus√£o do projeto. As se√ß√µes cujo cabe√ßalho come√ßa com **'Implementa√ß√£o'** indicam que o bloco de c√≥digo posterior requer funcionalidades adicionais que voc√™ deve desenvolver. Para cada parte do projeto ser√£o fornecidas instru√ß√µes e as diretrizes da implementa√ß√£o estar√£o marcadas no bloco de c√≥digo com uma express√£o `'TODO'`. 
# Por favor, leia cuidadosamente as instru√ß√µes!
# 
# Al√©m de implementa√ß√µes de c√≥digo, voc√™ ter√° de responder quest√µes relacionadas ao projeto e √† sua implementa√ß√£o. Cada se√ß√£o onde voc√™ responder√° uma quest√£o ter√° um cabe√ßalho com o termo **'Quest√£o X'**. Leia com aten√ß√£o as quest√µes e forne√ßa respostas completas nas caixas de texto que come√ßam com o termo **'Resposta:'**. A submiss√£o do seu projeto ser√° avaliada baseada nas suas resostas para cada uma das quest√µes al√©m das implementa√ß√µes que voc√™ disponibilizar.
# 
# >**Nota:** Por favor, especifique QUAL A VERS√ÉO DO PYTHON utilizada por voc√™ para a submiss√£o deste notebook. As c√©lulas "Code" e "Markdown" podem ser executadas utilizando o atalho do teclado **Shift + Enter**. Al√©m disso, as c√©lulas "Markdown" podem ser editadas clicando-se duas vezes na c√©lula.
# 

# ## Iniciando
# 
# Neste projeto, voc√™ utilizar√° diversos algoritmos de aprendizado supervisionado para modelar com precis√£o a remunera√ß√£o de indiv√≠duos utilizando dados coletados no censo americano de 1994. Voc√™ escolher√° o algoritmo mais adequado atrav√©s dos resultados preliminares e ir√° otimiz√°-lo para modelagem dos dados. O seu objetivo com esta implementa√ß√£o √© construir um modelo que pode predizer com precis√£o se um indiv√≠duo possui uma remunera√ß√£o superior a $50,000. Este tipo de tarefa pode surgir em organiza√ß√µes sem fins lucrativos que sobrevivem de doa√ß√µes. Entender a remunera√ß√£o de um indiv√≠duo pode ajudar a organiza√ß√£o o montante mais adequado para uma solicita√ß√£o de doa√ß√£o, ou ainda se eles realmente deveriam entrar em contato com a pessoa. Enquanto pode ser uma tarefa dif√≠cil determinar a faixa de renda de uma pesssoa de maneira direta, n√≥s podemos inferir estes valores atrav√©s de outros recursos dispon√≠veis publicamente. 
# 
# O conjunto de dados para este projeto se origina do [Reposit√≥rio de Machine Learning UCI](https://archive.ics.uci.edu/ml/datasets/Census+Income) e foi cedido por Ron Kohavi e Barry Becker, ap√≥s a sua publica√ß√£o no artigo _"Scaling Up the Accuracy of Naive-Bayes Classifiers: A Decision-Tree Hybrid"_. Voc√™ pode encontrar o artigo de Ron Kohavi [online](https://www.aaai.org/Papers/KDD/1996/KDD96-033.pdf). Os dados que investigaremos aqui possuem algumas pequenas modifica√ß√µes se comparados com os dados originais, como por exemplo a remo√ß√£o da funcionalidade `'fnlwgt'` e a remo√ß√£o de registros inconsistentes.
# 

# ----
# ## Explorando os dados
# Execute a c√©lula de c√≥digo abaixo para carregas as bibliotecas Python necess√°rias e carregas os dados do censo. Perceba que a √∫ltima coluna deste conjunto de dados, `'income'`, ser√° o r√≥tulo do nosso alvo (se um indiv√≠duo possui remunera√ß√£o igual ou maior do que $50,000 anualmente). Todas as outras colunas s√£o dados de cada ind√≠vduo na base de dados do censo.

# In[2]:


# Importe as bibliotecas necess√°rias para o projeto.
import numpy as np
import pandas as pd
from time import time
# from IPython.display import display # Permite a utiliza√ß√£o da fun√ß√£o display() para DataFrames.

# Importa√ß√£o da biblioteca de visualiza√ß√£o visuals.py
import visuals as vs

# Exibi√ß√£o amig√°vel para notebooks
# get_ipython().run_line_magic('matplotlib', 'inline')

# Carregando os dados do Censo
data = pd.read_csv("census.csv")

# Sucesso - Exibindo o primeiro registro
print(data.head(n=1))


# ### Implementa√ß√£o: Explorando os Dados
# 
# Uma investiga√ß√£o superficial da massa de dados determinar√° quantos indiv√≠duos se enquadram em cada grupo e nos dir√° sobre o percentual destes indiv√∫dos com remunera√ß√£o anual superior √† \$50,000. No c√≥digo abaixo, voc√™ precisar√° calcular o seguinte:
# - O n√∫mero total de registros, `'n_records'`
# - O n√∫mero de indiv√≠duos com remunera√ß√£o anual superior √† \$50,000, `'n_greater_50k'`.
# - O n√∫mero de indiv√≠duos com remunera√ß√£o anual at√© \$50,000, `'n_at_most_50k'`.
# - O percentual de indiv√≠duos com remunera√ß√£o anual superior √† \$50,000, `'greater_percent'`.
# 
# ** DICA: ** Voc√™ pode precisar olhar a tabela acima para entender como os registros da coluna `'income'` est√£o formatados.

# In[3]:


# TODO: N√∫mero total de registros.
n_records = data.shape[0]

# TODO: N√∫mero de registros com remunera√ß√£o anual superior √† $50,000
n_greater_50k = data[data.income == '>50K'].shape[0]

# TODO: O n√∫mero de registros com remunera√ß√£o anual at√© $50,000
n_at_most_50k = data[data.income == '<=50K'].shape[0]

# TODO: O percentual de indiv√≠duos com remunera√ß√£o anual superior √† $50,000
greater_percent = (n_greater_50k/n_records)*100

# Exibindo os resultados
print("Total number of records: {}".format(n_records))
print("Individuals making more than $50,000: {}".format(n_greater_50k))
print("Individuals making at most $50,000: {}".format(n_at_most_50k))
print("Percentage of individuals making more than $50,000: {:.2f}%".format(greater_percent))


# ** Explorando as colunas **
# * **age**: cont√≠nuo. 
# * **workclass**: Private, Self-emp-not-inc, Self-emp-inc, Federal-gov, Local-gov, State-gov, Without-pay, Never-worked. 
# * **education**: Bachelors, Some-college, 11th, HS-grad, Prof-school, Assoc-acdm, Assoc-voc, 9th, 7th-8th, 12th, Masters, 1st-4th, 10th, Doctorate, 5th-6th, Preschool. 
# * **education-num**: cont√≠nuo. 
# * **marital-status**: Married-civ-spouse, Divorced, Never-married, Separated, Widowed, Married-spouse-absent, Married-AF-spouse. 
# * **occupation**: Tech-support, Craft-repair, Other-service, Sales, Exec-managerial, Prof-specialty, Handlers-cleaners, Machine-op-inspct, Adm-clerical, Farming-fishing, Transport-moving, Priv-house-serv, Protective-serv, Armed-Forces. 
# * **relationship**: Wife, Own-child, Husband, Not-in-family, Other-relative, Unmarried. 
# * **race**: Black, White, Asian-Pac-Islander, Amer-Indian-Eskimo, Other. 
# * **sex**: Female, Male. 
# * **capital-gain**: cont√≠nuo. 
# * **capital-loss**: cont√≠nuo. 
# * **hours-per-week**: cont√≠nuo. 
# * **native-country**: United-States, Cambodia, England, Puerto-Rico, Canada, Germany, Outlying-US(Guam-USVI-etc), India, Japan, Greece, South, China, Cuba, Iran, Honduras, Philippines, Italy, Poland, Jamaica, Vietnam, Mexico, Portugal, Ireland, France, Dominican-Republic, Laos, Ecuador, Taiwan, Haiti, Columbia, Hungary, Guatemala, Nicaragua, Scotland, Thailand, Yugoslavia, El-Salvador, Trinadad&Tobago, Peru, Hong, Holand-Netherlands.

# ----
# ## Preparando os dados
# Antes de que os dados possam ser utilizados como input para algoritmos de machine learning, muitas vezes eles precisam ser tratados, formatados e reestruturados ‚Äî este processo √© conhecido como **pr√©-processamento**. Felizmente neste conjunto de dados n√£o existem registros inconsistentes para tratamento, por√©m algumas colunas precisam ser ajustadas. Este pr√©-processamento pode ajudar muito com o resultado e poder de predi√ß√£o de quase todos os algoritmos de aprendizado.

# ### Transformando os principais desvios das colunas cont√≠nuas
# Um conjunto de dados pode conter ao menos uma coluna onde os valores tendem a se pr√≥ximar para um √∫nico n√∫mero, mas tamb√©m podem conter registros com o mesmo atributo contendo um valor muito maior ou muito menor do que esta tend√™ncia. Algoritmos podem ser sens√≠veis para estes casos de distribui√ß√£o de valores e este fator pode prejudicar sua performance se a distribui√ß√£o n√£o estiver normalizada de maneira adequada. Com o conjunto de dados do censo, dois atributos se encaixam nesta descri√ß√£o: '`capital-gain'` e `'capital-loss'`.
# 
# Execute o c√≥digo da c√©lula abaixo para plotar um histograma destes dois atributos. Repare na distribui√ß√£o destes valores.

# In[4]:


# Dividindo os dados entre features e coluna alvo
income_raw = data['income']
features_raw = data.drop('income', axis = 1)

# Visualizando os principais desvios das colunas cont√≠nuas entre os dados
# vs.distribution(data)


# Para atributos com distribui√ß√£o muito distorcida, tais como `'capital-gain'` e `'capital-loss'`, √© uma pr√°tica comum aplicar uma <a href="https://en.wikipedia.org/wiki/Data_transformation_(statistics)">transforma√ß√£o logar√≠tmica</a> nos dados para que os valores muito grandes e muito pequenos n√£o afetem a performance do algoritmo de aprendizado. Usar a transforma√ß√£o logar√≠tmica reduz significativamente os limites dos valores afetados pelos outliers (valores muito grandes ou muito pequenos). Deve-se tomar cuidado ao aplicar esta transforma√ß√£o, poir o logaritmo de `0` √© indefinido, portanto temos que incrementar os valores em uma pequena quantia acima de `0` para aplicar o logaritmo adequadamente.
# 
# Execute o c√≥digo da c√©lula abaixo para realizar a transforma√ß√£o nos dados e visualizar os resultados. De novo, note os valores limite e como os valores est√£o distribu√≠dos.

# In[5]:


# Aplicando a transforma√ß√£o de log nos registros distorcidos.
skewed = ['capital-gain', 'capital-loss']
features_log_transformed = pd.DataFrame(data = features_raw)
features_log_transformed[skewed] = features_raw[skewed].apply(lambda x: np.log(x + 1))

# Visualizando as novas distribui√ß√µes ap√≥s a transforma√ß√£o.
# vs.distribution(features_log_transformed, transformed = True)


# ### Normalizando atributos num√©ricos
# Al√©m das transforma√ß√µes em atributos distorcidos, √© uma boa pr√°tica comum realizar algum tipo de adapta√ß√£o de escala nos atributos num√©ricos. Ajustar a escala nos dados n√£o modifica o formato da distribui√ß√£o de cada coluna (tais como `'capital-gain'` ou `'capital-loss'` acima); no entanto, a normaliza√ß√£o garante que cada atributo ser√° tratado com o mesmo peso durante a aplica√ß√£o de aprendizado supervisionado. Note que uma vez aplicada a escala, a observa√ß√£o dos dados n√£o ter√° o significado original, como exemplificado abaixo.
# 
# Execute o c√≥digo da c√©lula abaixo para normalizar cada atributo num√©rico, n√≥s usaremos ara isso a [`sklearn.preprocessing.MinMaxScaler`](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html).

# In[6]:


# Importando sklearn.preprocessing.StandardScaler
from sklearn.preprocessing import MinMaxScaler

# Inicializando um aplicador de escala e aplicando em seguida aos atributos
scaler = MinMaxScaler() # default=(0, 1)
numerical = ['age', 'education-num', 'capital-gain', 'capital-loss', 'hours-per-week']

features_log_minmax_transform = pd.DataFrame(data = features_log_transformed)
features_log_minmax_transform[numerical] = scaler.fit_transform(features_log_transformed[numerical])

# Exibindo um exemplo de registro com a escala aplicada
print(features_log_minmax_transform.head(n=5))


# ### Implementa√ß√£o: Pr√©-processamento dos dados
# 
# A partir da tabela em **Explorando os dados** acima, n√≥s podemos observar que existem diversos atributos n√£o-num√©ricos para cada registro. Usualmente, algoritmos de aprendizado esperam que os inputs sejam num√©ricos, o que requer que os atributos n√£o num√©ricos (chamados de *vari√°veis de categoria*) sejam convertidos. Uma maneira popular de converter as vari√°veis de categoria √© utilizar a estrat√©gia **one-hot encoding**. Esta estrat√©gia cria uma vari√°vel para cada categoria poss√≠vel de cada atributo n√£o num√©rico. Por exemplo, assuma que `algumAtributo` possu√≠ tr√™s valores poss√≠veis: `A`, `B`, ou `C`. N√≥s ent√£o transformamos este atributo em tr√™s novos atributos: `algumAtributo_A`, `algumAtributo_B` e `algumAtributo_C`.
# 
# 
# |   | algumAtributo |                    | algumAtributo_A | algumAtributo_B | algumAtributo_C |
# | :-: | :-: |                            | :-: | :-: | :-: |
# | 0 |  B  |  | 0 | 1 | 0 |
# | 1 |  C  | ----> one-hot encode ----> | 0 | 0 | 1 |
# | 2 |  A  |  | 1 | 0 | 0 |
# 
# Al√©m disso, assim como os atributos n√£o-num√©ricos, precisaremos converter a coluna alvo n√£o-num√©rica, `'income'`, para valores num√©ricos para que o algoritmo de aprendizado funcione. Uma vez que s√≥ existem duas categorias poss√≠veis para esta coluna ("<=50K" e ">50K"), n√≥s podemos evitar a utiliza√ß√£o do one-hot encoding e simplesmente transformar estas duas categorias para `0` e `1`, respectivamente. No trecho de c√≥digo abaixo, voc√™ precisar√° implementar o seguinte:
#  - Utilizar [`pandas.get_dummies()`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html?highlight=get_dummies#pandas.get_dummies) para realizar o one-hot encoding nos dados da `'features_log_minmax_transform'`.
#  - Converter a coluna alvo `'income_raw'` para re.
#    - Transforme os registros com "<=50K" para `0` e os registros com ">50K" para `1`.

# In[7]:


# TODO: Utilize o one-hot encoding nos dados em 'features_log_minmax_transform' utilizando pandas.get_dummies()
features_final = pd.get_dummies(features_log_minmax_transform)

# TODO: Fa√ßa o encode da coluna 'income_raw' para valores num√©ricos
income = income_raw.replace('>50K', 1).replace('<=50K', 0)

# Exiba o n√∫mero de colunas depois do one-hot encoding
encoded = list(features_final.columns)
print("{} total features after one-hot encoding.".format(len(encoded)))

# Descomente a linha abaixo para ver as colunas ap√≥s o encode
print(encoded)


# ### Embaralhar e dividir os dados
# Agora todas as _vari√°veis de categoria_ foram convertidas em atributos num√©ricos e todos os atributos num√©ricos foram normalizados. Como sempre, n√≥s agora dividiremos os dados entre conjuntos de treinamento e de teste. 80% dos dados ser√£o utilizados para treinamento e 20% para teste.
# 
# Execute o c√≥digo da c√©lula abaixo para realizar divis√£o.

# In[8]:


# Importar train_test_split
from sklearn.model_selection import train_test_split

# Dividir os 'atributos' e 'income' entre conjuntos de treinamento e de testes.
X_train, X_test, y_train, y_test = train_test_split(features_final, 
                                                    income, 
                                                    test_size = 0.2, 
                                                    random_state = 0)

# Show the results of the split
print("Training set has {} samples.".format(X_train.shape[0]))
print("Testing set has {} samples.".format(X_test.shape[0]))


# ----
# ## Avaliando a performance do modelo
# Nesta se√ß√£o n√≥s investigaremos quatro algoritmos diferentes e determinaremos qual deles √© melhor para a modelagem dos dados. Tr√™s destes algoritmos ser√£o algoritmos de aprendizado supervisionado de sua escolha e o quarto algoritmo √© conhecido como *naive predictor*.

# ### M√©tricas e o Naive predictor
# 
# *CharityML*, equpada com sua pesquisa, sabe que os indiv√≠duos que fazem mais do que \$50,000 possuem maior probabilidade de doar para a sua campanha de caridade. Por conta disto, a *CharityML* est√° particularmente interessada em predizer com acur√°cia quais indiv√≠duos possuem remunera√ß√£o acima de \$50,000. Parece que utilizar **acur√°cia (accuracy)** como uma m√©trica para avaliar a performance de um modelo √© um par√¢metro adequado. Al√©m disso, identificar algu√©m que *n√£o possui* remunera√ß√£o acima de \$50,000 como algu√©m que recebe acima deste valor seria ruim para a *CharityML*, uma vez que eles est√£o procurando por indiv√≠duos que desejam doar. Com isso, a habilidade do modelo em predizer com preis√£o aqueles que possuem a remunera√ß√£o acima dos \$50,000 √© *mais importante* do que a habilidade de realizar o **recall** destes indiv√≠duos. N√≥s podemos utilizar a f√≥rmula **F-beta score** como uma m√©trica que considera ambos: precision e recall.
# 
# 
# $$ F_{\beta} = (1 + \beta^2) \cdot \frac{precision \cdot recall}{\left( \beta^2 \cdot precision \right) + recall} $$
# 
# Em particular, quando $\beta = 0.5$, maior √™nfase √© atribu√≠da para a vari√°vel precision. Isso √© chamado de **F$_{0.5}$ score** (ou F-score, simplificando).
# 
# Analisando a distribui√ß√£o de classes (aqueles que possuem remunera√ß√£o at√© \$50,000 e aqueles que possuem remunera√ß√£o superior), fica claro que a maioria dos indiv√≠duos n√£o possui remunera√ß√£o acima de \$50,000. Isto pode ter grande impacto na **acur√°cia (accuracy)**, uma vez que n√≥s poder√≠amos simplesmente dizer *"Esta pessoa n√£o possui remunera√ß√£o acima de \$50,000"* e estar certos em boa parte das vezes, sem ao menos olhar os dados! Fazer este tipo de afirma√ß√£o seria chamado de **naive**, uma vez que n√£o consideramos nenhuma informa√ß√£o para balisar este argumento. √â sempre importante considerar a *naive prediction* para seu conjunto de dados, para ajudar a estabelecer um benchmark para an√°lise da performance dos modelos. Com isso, sabemos que utilizar a naive prediction n√£o traria resultado algum: Se a predi√ß√£o apontasse que todas as pessoas possuem remunera√ß√£o inferior √† \$50,000, a *CharityML* n√£o identificaria ningu√©m como potencial doador. 
# 
# 
# 
# #### Nota: Revisando: accuracy, precision e recall
# 
# ** Accuracy ** mede com que frequ√™ncia o classificador faz a predi√ß√£o correta. √â a propor√ß√£o entre o n√∫mero de predi√ß√µes corretas e o n√∫mero total de predi√ß√µes (o n√∫mero de registros testados).
# 
# ** Precision ** informa qual a propor√ß√£o de mensagens classificamos como spam eram realmente spam. Ou seja, √© a propor√ß√£o de verdadeiros positivos (mensagens classificadas como spam que eram realmente spam) sobre todos os positivos (todas as palavras classificadas como spam, independente se a classifica√ß√£o estava correta), em outras palavras, √© a propor√ß√£o
# 
# `[Verdadeiros positivos/(Verdadeiros positivos + Falso positivos)]`
# 
# ** Recall(sensibilidade)** nos informa qual a propor√ß√£o das mensagens que eram spam que foram corretamente classificadas como spam. √â a propor√ß√£o entre os verdadeiros positivos (classificados como spam, que realmente eram spam) sobre todas as palavras que realmente eram spam. Em outras palavras, √© a propor√ß√£o entre
# 
# `[Verdadeiros positivos/(Verdadeiros positivos + Falso negativos)]`
# 
# Para problemas de classifica√ß√£o distorcidos em suas distribui√ß√µes, como no nosso caso, por exemplo, se tiv√©ssemos 100 mensagems de texto e apenas 2 fossem spam e todas as outras n√£o fossem, a "accuracy" por si s√≥ n√£o seria uma m√©trica t√£o boa. N√≥s poderiamos classificar 90 mensagems como "n√£o-spam" (incluindo as 2 que eram spam mas que teriam sido classificadas como n√£o-spam e, por tanto, seriam falso negativas.) e 10 mensagems como spam (todas as 10 falso positivas) e ainda assim teriamos uma boa pontua√ß√£o de accuracy. Para estess casos, precision e recall s√£o muito √∫teis. Estas duas m√©tricas podem ser combinadas para resgatar o F1 score, que √© calculado atrav√©s da m√©dia(harm√¥nica) dos valores de precision e de recall. Este score pode variar entre 0 e 1, sendo 1 o melhor resultado poss√≠vel para o F1 score (consideramos a m√©dia harm√¥nica pois estamos lidando com propor√ß√µes).

# ### Quest√£o 1 - Performance do Naive Predictor
# * Se escolhessemos um modelo que sempre prediz que um indiv√≠duo possui remunera√ß√£o acima de $50,000, qual seria a accuracy e o F-score considerando este conjunto de dados? Voc√™ dever√° utilizar o c√≥digo da c√©lula abaixo e atribuir os seus resultados para as vari√°veis `'accuracy'` e `'fscore'` que ser√£o usadas posteriormente.
# 
# ** Por favor, note ** que o prop√≥sito ao gerar um naive predictor √© simplesmente exibir como um modelo sem nenhuma intelig√™ncia se comportaria. No mundo real, idealmente o seu modelo de base ser√° o resultado de um modelo anterior ou poderia ser baseado em um paper no qual voc√™ se basearia para melhorar. Quando n√£o houver qualquer benchmark de modelo, utilizar um naive predictor ser√° melhor do que uma escolha aleat√≥ria.
# 
# ** DICA: ** 
# 
# * Quando temos um modelo que sempre prediz '1' (e.x o indiv√≠duo possui remunera√ß√£o superior √† 50k) ent√£o nosso modelo n√£o ter√° Verdadeiros Negativos ou Falso Negativos, pois n√≥s n√£o estaremos afirmando que qualquer dos valores √© negativo (ou '0') durante a predi√ß√£o. Com isso, nossa accuracy neste caso se torna o mesmo valor da precision (Verdadeiros positivos/ (Verdadeiros positivos + Falso positivos)) pois cada predi√ß√£o que fizemos com o valor '1' que deveria ter o valor '0' se torna um falso positivo; nosso denominador neste caso √© o n√∫mero total de registros.
# * Nossa pontua√ß√£o de Recall(Verdadeiros positivos/(Verdadeiros Positivos + Falsos negativos)) ser√° 1 pois n√£o teremos Falsos negativos.

# In[16]:


'''
TP = np.sum(income) # Contando pois este √© o caso "naive". Note que 'income' s√£o os dados 'income_raw' convertidos
para valores num√©ricos durante o passo de pr√©-processamento de dados.
FP = income.count() - TP # Espec√≠fico para o caso naive

TN = 0 # Sem predi√ß√µes negativas para o caso naive
FN = 0 # Sem predi√ß√µes negativas para o caso naive
'''
TP = np.sum(income) # Numero de Predi√ß√µes Corretas
FP = income.count() - TP # Numero de total de Predi√ß√µes - Predi√ß√µes Corretas = Falsos Positivos

# TODO: Calcular accuracy, precision e recall
accuracy = TP / income.count()
recall = 1 # N√£o temos Falsos Negativos ent√£o seria TP/TP
precision = TP / (TP + FP)

beta = 0.5**2

# TODO: Calcular o F-score utilizando a f√≥rmula acima para o beta = 0.5 e os valores corretos de precision e recall.
fscore = (1+beta)*((precision*recall)/((beta*precision)+recall))

#ùêπùõΩ=(1+ùõΩ2)‚ãÖùëùùëüùëíùëêùëñùë†ùëñùëúùëõ‚ãÖùëüùëíùëêùëéùëôùëô(ùõΩ2‚ãÖùëùùëüùëíùëêùëñùë†ùëñùëúùëõ)+ùëüùëíùëêùëéùëôùëô

# Exibir os resultados 
print("Naive Predictor: [Accuracy score: {:.4f}, F-score: {:.4f}]".format(accuracy, fscore))


# ###  Modelos de Aprendizado Supervisionado
# **Estes s√£o alguns dos modelos de aprendizado supervisionado dispon√≠veis em** [`scikit-learn`](http://scikit-learn.org/stable/supervised_learning.html)
# - Gaussian Naive Bayes (GaussianNB)
# - Decision Trees (√Årvores de decis√£o)
# - Ensemble Methods (Bagging, AdaBoost, Random Forest, Gradient Boosting)
# - K-Nearest Neighbors (KNeighbors)
# - Stochastic Gradient Descent Classifier (SGDC)
# - Support Vector Machines (SVM)
# - Logistic Regression

# ### Quest√£o 2 - Aplica√ß√£o do Modelo
# Liste tr√™s dos modelos de aprendizado supervisionado acima que s√£o apropriados para este problema que voc√™ ir√° testar nos dados do censo. Para cada modelo escolhido
# 
# - Descreva uma situa√ß√£o do mundo real onde este modelo pode ser utilizado. 
# - Quais s√£o as vantagems da utiliza√ß√£o deste modelo; quando ele performa bem?
# - Quais s√£o as fraquesas do modelo; quando ele performa mal?
# - O que torna este modelo um bom candidato para o problema, considerando o que voc√™ sabe sobre o conjunto de dados?
# 
# ** DICA: **
# 
# Estruture sua resposta no mesmo formato acima^, com 4 partes para cada um dos modelos que voc√™ escolher. Por favor, inclua refer√™ncias em cada uma das respostas.

# ### Gaussian Naive Bayes 
# - **GaussianNB**
# ###### Descreva uma situa√ß√£o do mundo real onde este modelo pode ser utilizado.
# - Geralmente utilizado para tarefas de classifica√ß√£o envolvendo textos, frases e senten√ßas. Alguns exemplos disto s√£o classifica√ß√£o de emails como spam comparando palavras comumente utilizadas em spam com o conte√∫do do email. Tambem pode ser utilizado para classificar categorias, baseado nos atributos como este exemplo de Sex Classification, baseado na altura/peso/tamanho do p√© (https://en.wikipedia.org/wiki/Naive_Bayes_classifier#Sex_classification).
# - [Fonte](https://en.wikipedia.org/wiki/Naive_Bayes_classifier)
# ###### Quais s√£o as vantagems da utiliza√ß√£o deste modelo; quando ele performa bem?
# - Simplicidade de implementa√ß√£o.
# - Alta competividade.
# ###### Quais s√£o as fraquesas do modelo; quando ele performa mal?
# - Quando os atributos n√£o s√£o relacionados entre si, n√£o tem um bom resultado.
# - Com poucos dados de treino, pode se gerar um bias muito alto.
# ###### O que torna este modelo um bom candidato para o problema, considerando o que voc√™ sabe sobre o conjunto de dados?
# - Acredito que como os dados est√£o bem relacionados entre si, e que os doadores propensos a doar tem o mesmo padr√£o de comportamento espero que este algoritimo ter√° uma boa performance.
# 
# ### Decision Trees 
# - **√Årvores de decis√£o**
# ###### Descreva uma situa√ß√£o do mundo real onde este modelo pode ser utilizado.
# - Muitas s√£o as situa√ß√µes em que Decision Trees s√£o usadas. Podemos citar o campo m√©dico¬π, onde foi utilizada para determinar a probabilidade de uma doen√ßa ocorrer, tambem √© utilizada para reconhecimento de objetos em imagens¬≤ e at√© mesmo para prever quais a√ß√µes s√£o saudaveis para compra¬≥.
# - ¬π - https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4466856/
# - ¬≤ - http://dimatura.net/publications/dtlbp_maturana_soto_accv10.pdf
# - ¬≥ - https://www.quantinsti.com/blog/use-decision-trees-machine-learning-predict-stock-movements		
# ###### Quais s√£o as vantagems da utiliza√ß√£o deste modelo; quando ele performa bem?
# - Relativamente simples de entender e implementar.
# - N√£o requer grandes prepara√ß√µes de dados, lida bem com dados numericos e categoricos.
# ###### Quais s√£o as fraquesas do modelo; quando ele performa mal?
# - Decision Trees complexas n√£o generalizam muito bem, causando overfitting.
# - Sensivel aos dados de input, uma pequena varia√ß√£o pode resultar em um resultado muito diferente.
# - Pode criar arvores com um vi√©s errado, se uma classe dominar o dataset.
# ###### O que torna este modelo um bom candidato para o problema, considerando o que voc√™ sabe sobre o conjunto de dados?
# - Por lidar com dados categoricos e numericos, caso do nosso dataset, e por ter uma facil implementa√ß√£o e interpreta√ß√£o suponho que ser√° um bom modelo para que eu possa analisar, e entender a l√≥gica.
# 	
# ### Support Vector Machines
# - **SVM**
# ###### Descreva uma situa√ß√£o do mundo real onde este modelo pode ser utilizado.
# - Encontramos alguns exemplos de aplica√ß√£o em trabalhos com imagem como Reconhecimento de Faces¬π e Reconhecimento de Escrita¬≤.
# - ¬π - https://papers.nips.cc/paper/1609-support-vector-machines-applied-to-face-recognition.pdf
# - ¬≤ - https://thesai.org/Downloads/Volume6No11/Paper_9-Handwriting_Word_Recognition_Based_on_SVM_Classifier.pdf
# ###### Quais s√£o as vantagems da utiliza√ß√£o deste modelo; quando ele performa bem?
# - Tem uma performance muito boa para datasets com muitas dimens√µes.
# - Trabalha bem com dados com ampla margem de separa√ß√£o.
# ###### Quais s√£o as fraquesas do modelo; quando ele performa mal?
# - Quando temos um dataset muito largo, a performance √© impactada.
# - Quando os dados se sobrep√µe muito, n√£o tem bom resultado.
# ###### O que torna este modelo um bom candidato para o problema, considerando o que voc√™ sabe sobre o conjunto de dados?
# - Por ser um modelo que trabalha bem com "High Dimentions", e ter bom desempenho em classifica√ß√£o binaria (nosso caso) acredito que ter√° uma vantagem muito boa.

# ### Implementa√ß√£o - Criando um Pipeline de Treinamento e Predi√ß√£o
# Para avaliar adequadamente a performance de cada um dos modelos que voc√™ escolheu √© importante que voc√™ crie um pipeline de treinamento e predi√ß√£o que te permite de maneira r√°pida e eficiente treinar os modelos utilizando v√°rios tamanhos de conjuntos de dados para treinamento, al√©m de performar predi√ß√µes nos dados de teste. Sua implementa√ß√£o aqui ser√° utilizada na pr√≥xima se√ß√£o. No bloco de c√≥digo abaixo, voc√™ precisar√° implementar o seguinte:
#  - Importar `fbeta_score` e `accuracy_score` de [`sklearn.metrics`](http://scikit-learn.org/stable/modules/classes.html#sklearn-metrics-metrics).
#  - Adapte o algoritmo para os dados de treinamento e registre o tempo de treinamento. 
#  - Realize predi√ß√µes nos dados de teste `X_test`, e tamb√©m nos 300 primeiros pontos de treinamento `X_train[:300]`.
#    - Registre o tempo total de predi√ß√£o. 
#  - Calcule a acur√°cia tanto para o conjundo de dados de treino quanto para o conjunto de testes.
#  - Calcule o F-score para os dois conjuntos de dados: treino e testes. 
#    - Garanta que voc√™ configurou o par√¢metro `beta`! 

# In[ ]:


# TODO: Import two metrics from sklearn - fbeta_score and accuracy_score
from sklearn.metrics import fbeta_score, accuracy_score
def train_predict(learner, sample_size, X_train, y_train, X_test, y_test):

    '''
    inputs:
       - learner: the learning algorithm to be trained and predicted on
       - sample_size: the size of samples (number) to be drawn from training set
       - X_train: features training set
       - y_train: income training set
       - X_test: features testing set
       - y_test: income testing set
    '''
    
    results = {}
    
    # TODO: Fit the learner to the training data using slicing with 'sample_size' using .fit(training_features[:], training_labels[:])
    start = time() # Get start time
    learner = learner.fit(X_train[:sample_size], y_test[:sample_size])
    end = time() # Get end time
    
    # TODO: Calculate the training time
    results['train_time'] = end - start
        
    # TODO: Get the predictions on the test set(X_test),
    #       then get predictions on the first 300 training samples(X_train) using .predict()
    start = time() # Get start time
    predictions_test = learner.predict(X_test)
    predictions_train = learner.predict(X_train[:300])
    end = time() # Get end time
    
    # TODO: Calculate the total prediction time
    results['pred_time'] = end - start
            
    # TODO: Compute accuracy on the first 300 training samples which is y_train[:300]
    results['acc_train'] = learner.accuracy_score(y_train[:300], predictions_train)
        
    # TODO: Compute accuracy on test set using accuracy_score()
    results['acc_test'] = learner.accuracy_score(y_test, predictions_test)
    
    # TODO: Compute F-score on the the first 300 training samples using fbeta_score()
    results['f_train'] = learner.fbeta_score(y_train[:300], predictions_train, 0.5)
        
    # TODO: Compute F-score on the test set which is y_test
    results['f_test'] = learner.fbeta_score(y_test, predictions_test, 0.5)
       
    # Success
    print("{} trained on {} samples.".format(learner.__class__.__name__, sample_size))
        
    # Return the results
    return results


# ### Implementa√ß√£o: Valida√ß√£o inicial do modelo
# No c√≥digo da c√©lular, voc√™ precisar√° implementar o seguinte:
# - Importar os tr√™s modelos de aprendizado supervisionado que voc√™ escolheu na se√ß√£o anterior 
# - Inicializar os tr√™s modelos e armazen√°-los em `'clf_A'`, `'clf_B'`, e `'clf_C'`. 
#   - Utilize um `'random_state'` para cada modelo que voc√™ utilizar, caso seja fornecido.
#   - **Nota:** Utilize as configura√ß√µes padr√£o para cada modelo - voc√™ otimizar√° um modelo espec√≠fico em uma se√ß√£o posterior
# - Calcule o n√∫mero de registros equivalentes √† 1%, 10%, e 100% dos dados de treinamento.
#   - Armazene estes valores em `'samples_1'`, `'samples_10'`, e `'samples_100'` respectivamente.
# 
# **Nota:** Dependendo do algoritmo de sua escolha, a implementa√ß√£o abaixo pode demorar algum tempo para executar!

# In[ ]:


# TODO: Importe os tr√™s modelos de aprendizado supervisionado da sklearn
#Gaussian Naive Bayes
from sklearn.naive_bayes import GaussianNB
#Decision Trees
from sklearn.tree import DecisionTreeClassifier
#Support Vector Machines
from sklearn.svm import SVC

# TODO: Inicialize os tr√™s modelos
clf_A = GaussianNB()
clf_B = DecisionTreeClassifier(random_state=0)
clf_C = SVC(random_state=0, gamma="auto")


# TODO: Calcule o n√∫mero de amostras para 1%, 10%, e 100% dos dados de treinamento
# HINT: samples_100 √© todo o conjunto de treinamento e.x.: len(y_train)
# HINT: samples_10 √© 10% de samples_100
# HINT: samples_1 √© 1% de samples_100
samples_100 = int(len(X_train))
samples_10 = int(len(X_train) / 10)
samples_1 = int(len(X_train) / 100)

# Colete os resultados dos algoritmos de aprendizado
results = {}
for clf in [clf_A, clf_B, clf_C]:
    clf_name = clf.__class__.__name__
    results[clf_name] = {}
    for i, samples in enumerate([samples_1, samples_10, samples_100]):
        print("Testing {} for {} samples".format(clf, samples))
        results[clf_name][i] = train_predict(clf, samples, X_train, y_train, X_test, y_test)

# Run metrics visualization for the three supervised learning models chosen
vs.evaluate(results, accuracy, fscore)


# TODO: Importar 'GridSearchCV', 'make_scorer', e qualquer biblioteca necess√°ria
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import make_scorer, fbeta_score

# TODO: Inicializar o classificador
clf = DecisionTreeClassifier(random_state=0)

# TODO: Criar a lista de par√¢metros que voc√™ quer otimizar, utilizando um dicion√°rio, caso necess√°rio.
# HINT: parameters = {'parameter_1': [value1, value2], 'parameter_2': [value1, value2]}
parameters = {'criterion': ['gini', 'entropy'],
              'splitter': ['best', 'random'],
              'max_depth': [2, 3, 4, 5, 10, 25, 50],
              'min_samples_split': [2, 3, 4, 8, 16, 32]}

# TODO: Criar um objeto fbeta_score utilizando make_scorer()
scorer = make_scorer(fbeta_score, beta=0.5)

# TODO: Realizar uma busca grid no classificador utilizando o 'scorer' como o m√©todo de score no GridSearchCV()
grid_obj = GridSearchCV(clf, parameters, scorering=0)

# TODO: Adequar o objeto da busca grid como os dados para treinamento e encontrar os par√¢metros √≥timos utilizando fit()
grid_fit = grid_obj.fit(X_train, y_train)

# Recuperar o estimador
best_clf = grid_fit.best_estimator_

# Realizar predi√ß√µes utilizando o modelo n√£o otimizado e modelar
predictions = (clf.fit(X_train, y_train)).predict(X_test)
best_predictions = best_clf.predict(X_test)

# Reportar os scores de antes e de depois
print("Unoptimized model\n------")
print("Accuracy score on testing data: {:.4f}".format(accuracy_score(y_test, predictions)))
print("F-score on testing data: {:.4f}".format(fbeta_score(y_test, predictions, beta = 0.5)))
print("\nOptimized Model\n------")
print("Final accuracy score on the testing data: {:.4f}".format(accuracy_score(y_test, best_predictions)))
print("Final F-score on the testing data: {:.4f}".format(fbeta_score(y_test, best_predictions, beta = 0.5)))

model = DecisionTreeClassifier()

importances = DecisionTreeClassifier().feature_importances_
